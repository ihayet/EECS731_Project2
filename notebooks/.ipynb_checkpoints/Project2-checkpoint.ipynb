{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project 2:** Classifying players from William Shakespeare's Drama Lines\n",
    "\n",
    "**Author:** Ishrak Hayet<br>**Date:** 09/21/2020\n",
    "\n",
    "In this project, we work with a dataset containing the lines from William Shakespeare's plays. We also have a column that depicts the player who is saying a line. Our goal for this project will be to train a Natural Language Processing model with engineered features to identify a character from a given line.\n",
    "\n",
    "The data analysis and classification workflow will be as follows:\n",
    "\n",
    "1) Creating a wordcloud for each player to get a visual description of word frequencies for each player\n",
    "\n",
    "2) Engineering the following features from the dataset\n",
    "    a) \n",
    "\n",
    "3) Exploratory data analysis using the engineered features\n",
    "\n",
    "4) Splitting the dataset into training, validation and testing set\n",
    "\n",
    "5) Training the following classifiers using the engineered features\n",
    "\n",
    "6) Model evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** Importing the required packages and loading saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ISHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ISHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ISHRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Wordcloud packages\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "#NLP packages\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Model storage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the saved Shakespeare_Word2Vec.sav model using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/Shakespeare_Word2Vec.sav'\n",
    "Shakespeare_Word2Vec_Model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
       "0         1  Henry IV               NaN          NaN            NaN   \n",
       "1         2  Henry IV               NaN          NaN            NaN   \n",
       "2         3  Henry IV               NaN          NaN            NaN   \n",
       "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
       "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
       "\n",
       "                                          PlayerLine  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/raw/Shakespeare_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description of the columns of the dataset is as follows:\n",
    "\n",
    "**Dataline**: Sequence of numbers to identify an index\n",
    "\n",
    "**Play**: Name of the play from which we have the current play line\n",
    "\n",
    "**PlayerLineNumber**: This is the number of a line that is spoken by a player. A sequence of contiguous lines can be spoken by the same player and those will all be identified as the same line number. This can be thought of more like a paragraph for every instance of dialog for a player.\n",
    "\n",
    "**ActSceneLine**: This is a dot separated value consisting of three sub-values. The first sub-value represents the act number. The second sub-value represents the scene number. The third sub-value represents the line number.\n",
    "\n",
    "**Player**: Name of the player who is saying the current line\n",
    "\n",
    "**PlayerLine**: The line that is being spoken by the current player\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the datatypes for each of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataline              int64\n",
       "Play                 object\n",
       "PlayerLinenumber    float64\n",
       "ActSceneLine         object\n",
       "Player               object\n",
       "PlayerLine           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the Dataline column\n",
    "The Dataline column represents a monotonically increasing sequence for indexing the dataset. Since, we will not be using this indexing, we can drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Dataline' in data.columns:\n",
    "    data.drop(['Dataline'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing tuples with missing values of \"ActSceneLine\" and \"Player\"\n",
    "\n",
    "After taking a look at the dataset, we can be certain that the tuples having NaN values for \"ActSceneLine\" and \"Player\" contain lines that are not spoken by a player. These lines will not be useful since our goal is to identify players from spoken lines. So, we remove these tuples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, subset=['Player', 'ActSceneLine'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing PlayerLine\n",
    "\n",
    "Now, we will convert the PlayerLine words to lowercase for the convenience of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PlayerLine'] = data['PlayerLine'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove the punctuation marks from the PlayerLine column since these punctuation marks will not be useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PlayerLine'] = data['PlayerLine'].apply(lambda line: re.sub(r'[^A-Za-z0-9 ]', '', line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we will tokenize the PlayerLines by words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PlayerLine'] = data['PlayerLine'].apply(lambda line: word_tokenize(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will remove the stop words from the PlayerLine column since the stop words are also not useful for identifiability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "data['PlayerLine'] = data['PlayerLine'].apply(lambda line: [w for w in line if not w in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use lemmatization to find the root of words so that we are creating as much of a common lexical ground as possible regardless of the sentence structures. The reason for using lemmatization instead of stemming is because lemmatization derives more accurate roots (lemmas) of words since it performs a complete morphological analysis [1]. We will use the WordNet [2] lemmatizer from nltk to perform the lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PlayerLine'] = data['PlayerLine'].apply(lambda line: [WordNetLemmatizer().lemmatize(w) for w in line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4:** Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Encoding the Play column\n",
    "\n",
    "The \"Play\" column is a categorical variable and the values are strings. Since string values have a lot of entropy, these might not be useful for the classifer. Therefore, we encode the \"Play\" column into binary values. The reason for using binary encoder instead of one hot encoder is to reduce the number of columns. In one hot encoding we get as many number of columns as the number of unique values in a column. As a result, the classifier can suffer from the curse of dimensionality which suggests that when we have more features, we need higher number of data. On the other hand, binary encoder generates as many columns as the binary logarithm of the number of unique values. Consequently, we get exponentially fewer columns than that of one hot encoding. To further reduce the number of columns, we can join the encoded columns into a bitstring and each unique bitstring will represent a unique value of the \"Play\" column. Then, we can drop the \"Play\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "      <th>PlayEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>[shaken, wan, care]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>[find, time, frighted, peace, pant]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>[breathe, shortwinded, accent, new, broil]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.4</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>[commenced, strand, afar, remote]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.5</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>[thirsty, entrance, soil]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlayerLinenumber ActSceneLine         Player  \\\n",
       "3               1.0        1.1.1  KING HENRY IV   \n",
       "4               1.0        1.1.2  KING HENRY IV   \n",
       "5               1.0        1.1.3  KING HENRY IV   \n",
       "6               1.0        1.1.4  KING HENRY IV   \n",
       "7               1.0        1.1.5  KING HENRY IV   \n",
       "\n",
       "                                   PlayerLine PlayEncoded  \n",
       "3                         [shaken, wan, care]     0000001  \n",
       "4         [find, time, frighted, peace, pant]     0000001  \n",
       "5  [breathe, shortwinded, accent, new, broil]     0000001  \n",
       "6           [commenced, strand, afar, remote]     0000001  \n",
       "7                   [thirsty, entrance, soil]     0000001  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playEncoder = ce.BinaryEncoder()\n",
    "\n",
    "if 'Play' in data.columns:\n",
    "    encodedPlay = playEncoder.fit_transform(data['Play'])\n",
    "\n",
    "    data['PlayEncoded'] = encodedPlay.apply(lambda x: ''.join(x.astype(str)), axis=1)\n",
    "\n",
    "    data.drop(['Play'], axis=1, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding the Player column\n",
    "\n",
    "The \"Player\" column is our target feature. For the convenience of classification, let us encode the \"Player\" column using numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'col': 'Player', 'mapping': KING HENRY IV      1\n",
      "WESTMORELAND       2\n",
      "FALSTAFF           3\n",
      "PRINCE HENRY       4\n",
      "POINS              5\n",
      "                ... \n",
      "PERDITA          931\n",
      "DORCAS           932\n",
      "MOPSA            933\n",
      "Shepard          934\n",
      "NaN               -2\n",
      "Length: 935, dtype: int64, 'data_type': dtype('O')}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "      <th>PlayEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[shaken, wan, care]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>[find, time, frighted, peace, pant]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>[breathe, shortwinded, accent, new, broil]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>[commenced, strand, afar, remote]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[thirsty, entrance, soil]</td>\n",
       "      <td>0000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlayerLinenumber ActSceneLine  Player  \\\n",
       "3               1.0        1.1.1       1   \n",
       "4               1.0        1.1.2       1   \n",
       "5               1.0        1.1.3       1   \n",
       "6               1.0        1.1.4       1   \n",
       "7               1.0        1.1.5       1   \n",
       "\n",
       "                                   PlayerLine PlayEncoded  \n",
       "3                         [shaken, wan, care]     0000001  \n",
       "4         [find, time, frighted, peace, pant]     0000001  \n",
       "5  [breathe, shortwinded, accent, new, broil]     0000001  \n",
       "6           [commenced, strand, afar, remote]     0000001  \n",
       "7                   [thirsty, entrance, soil]     0000001  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if data.dtypes['Player'] == 'object':\n",
    "    playerEncoder = ce.OrdinalEncoder()\n",
    "    \n",
    "    data['Player'] = playerEncoder.fit_transform(data['Player'])\n",
    "\n",
    "print(playerEncoder.category_mapping)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decomposing the \"ActSceneLine\" column\n",
    "\n",
    "In the ActSceneLine column, we have values that represent act.scene.line. The act, scene and line numbers might be useful to give a hierarchical insight. Therefore, we decompose the \"ActSceneLine\" column into three different columns. Then, we can drop the \"ActSceneLine\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "      <th>PlayEncoded</th>\n",
       "      <th>Act</th>\n",
       "      <th>Scene</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[shaken, wan, care]</td>\n",
       "      <td>0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[find, time, frighted, peace, pant]</td>\n",
       "      <td>0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[breathe, shortwinded, accent, new, broil]</td>\n",
       "      <td>0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[commenced, strand, afar, remote]</td>\n",
       "      <td>0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[thirsty, entrance, soil]</td>\n",
       "      <td>0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlayerLinenumber  Player                                  PlayerLine  \\\n",
       "3               1.0       1                         [shaken, wan, care]   \n",
       "4               1.0       1         [find, time, frighted, peace, pant]   \n",
       "5               1.0       1  [breathe, shortwinded, accent, new, broil]   \n",
       "6               1.0       1           [commenced, strand, afar, remote]   \n",
       "7               1.0       1                   [thirsty, entrance, soil]   \n",
       "\n",
       "  PlayEncoded Act Scene Line  \n",
       "3     0000001   1     1    1  \n",
       "4     0000001   1     1    2  \n",
       "5     0000001   1     1    3  \n",
       "6     0000001   1     1    4  \n",
       "7     0000001   1     1    5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not set(['Act', 'Scene', 'Line']).issubset(set(data.columns)):\n",
    "    temp = data['ActSceneLine'].str.split('.', expand=True)\n",
    "    temp.columns = ['Act', 'Scene', 'Line']\n",
    "\n",
    "    data = pd.concat([data, temp], axis=1)\n",
    "\n",
    "if 'ActSceneLine' in data.columns:\n",
    "    data.drop(['ActSceneLine'], axis=1, inplace=True)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing the PlayerLine\n",
    "\n",
    "PlayerLine values are now a list of tokens. Such a list of strings is not a suitable feature for classifiers. So, we convert each token into vectors using the pretrained *Shakespeare_Word2Vec.sav* model. Then, we take the average of the list of words for every sentence to represent that sentence's vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSentenceVector(frame):    \n",
    "    vec = [Shakespeare_Word2Vec_Model.wv[w] for w in frame['PlayerLine']]\n",
    "    print(np.average(vec))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(computeSentenceVector, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5:** Exploring the Engineered Dataset using Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud Generation\n",
    "\n",
    "Wordclouds are an interesting technique to visualize word frequencies in a given text. Since our goal is to classify players from the other features, we will group the dataset by \"Player\" column and create a wordcloud for each player. This might be useful to explore the word usage frequencies for every player.\n",
    "\n",
    "Since there are many players, visualizing all of them at once might not be feasible. Therefore, we take a subset of players and create wordclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showWordCloud(frame):\n",
    "    cloudMask = np.array(Image.open(\"../data/external/william-shakespeare-black-silhouette.jpg\"))\n",
    "    \n",
    "    playerLine = \" \".join([w for line in frame['PlayerLine'] for w in line])\n",
    "    \n",
    "    wordCloud = WordCloud(max_font_size=100, background_color=\"white\", mask=cloudMask)\n",
    "    wordCloud.generate(playerLine)\n",
    "    \n",
    "    # Display the word cloud \n",
    "    ax = plt.gca()\n",
    "    ax.set_title(frame['Player'].iloc[0])\n",
    "    \n",
    "    plt.imshow(wordCloud, interpolation='bilinear')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedData = data.groupby(['Player'])\n",
    "\n",
    "groupKeys = list(groupedData.groups.keys())\n",
    "\n",
    "for i in range(0, 10):\n",
    "    showWordCloud(groupedData.get_group(groupKeys[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the wordclouds, we can see that the players having an incomplete silhouette of Shakespeare, have fewer lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6:** Classifying Players from the Rest of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['PlayerLinenumber', 'Act', 'Scene', 'Line', 'PlayEncoded']]\n",
    "y = data['Player']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmClassifier = SVC(class_weight='balanced')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 7:** Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://towardsdatascience.com/text-cleaning-methods-for-natural-language-processing-f2fc1796e8c7\n",
    "2. Princeton University \"About WordNet.\" WordNet (https://wordnet.princeton.edu/). Princeton University. 2010."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
